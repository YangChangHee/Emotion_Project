{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "visible-arrangement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "impressive-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "private_labels=np.load(\"Nohot_private_label.npy\")\n",
    "private_pixels=np.load(\"private_pixels.npy\")\n",
    "public_labels=np.load(\"Nohot_public_label.npy\")\n",
    "public_pixels=np.load(\"public_pixels.npy\")\n",
    "train_labels=np.load(\"Nohot_train_label.npy\")\n",
    "train_pixels=np.load(\"train_pixels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "pharmaceutical-sweden",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , y_train = train_pixels,train_labels\n",
    "X_valid , y_valid = public_pixels,public_labels\n",
    "X_test , y_test = private_pixels,private_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "environmental-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vals = np.mean(X_train, axis=0)\n",
    "std_val = np.std(X_train)\n",
    "\n",
    "X_train_centered = (X_train - mean_vals)/std_val\n",
    "X_valid_centered = (X_valid - mean_vals)/std_val\n",
    "X_test_centered = (X_test - mean_vals)/std_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "raising-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "input_data=torch.FloatTensor(X_train_centered)\n",
    "label=torch.LongTensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "straight-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data1=torch.FloatTensor(X_valid_centered)\n",
    "label1=torch.LongTensor(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "acoustic-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data2=torch.FloatTensor(X_test_centered)\n",
    "label2=torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "distant-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=input_data.transpose(1,3)\n",
    "input_data1=input_data1.transpose(1,3)\n",
    "input_data2=input_data2.transpose(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "roman-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "trainset = TensorDataset(input_data,label)\n",
    "valset = TensorDataset(input_data1,label1)\n",
    "testset = TensorDataset(input_data2,label2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fewer-projection",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition={'train':trainset,'val':valset,'test':testset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "mature-australian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cultural-lighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, nChannels,growthRate):\n",
    "        super(Bottleneck,self).__init__()\n",
    "        interChannels = 4*growthRate\n",
    "        self.bn1=nn.BatchNorm2d(nChannels)\n",
    "        self.conv1=nn.Conv2d(nChannels, interChannels,kernel_size=1,\n",
    "                            bias=False)\n",
    "        self.bn2=nn.BatchNorm2d(interChannels)\n",
    "        self.conv2 = nn.Conv2d(interChannels, growthRate, kernel_size=3,\n",
    "                               padding=1, bias=False)\n",
    "    def forward(self,x):\n",
    "        out = self.conv1(F.relu(self.bn1(x)))\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out = torch.cat((x, out), 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "weighted-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transition(nn.Module): # 반으로 줄여주는 작업임.\n",
    "    def __init__(self, nChannels, nOutChannels):\n",
    "        super(Transition, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(nChannels)\n",
    "        self.conv1 = nn.Conv2d(nChannels, nOutChannels, kernel_size=1,\n",
    "                               bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(F.relu(self.bn1(x)))\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "spoken-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, growthRate, depth, reduction, nClasses, bottleneck):\n",
    "        super(DenseNet, self).__init__()\n",
    "\n",
    "        nDenseBlocks = (depth-4) // 3 # 만약 depth가 100이라면 32\n",
    "        if bottleneck:\n",
    "            nDenseBlocks //= 2 # Bottleneck이 있다면  16\n",
    "\n",
    "        nChannels = 2*growthRate # growthRate 12\n",
    "        self.conv1 = nn.Conv2d(1, nChannels, kernel_size=3, padding=1,\n",
    "                               bias=False)\n",
    "        # 1, 24, 50, 50\n",
    "        \n",
    "        #nDenseBlock => 16(Bottleneck)\n",
    "        #nChannel => 24\n",
    "        #growthRath => 12\n",
    "        self.dense1 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n",
    "        # 1, 216, 50, 50\n",
    "        # 12*18 => 12 == growthRath \n",
    "        nChannels += nDenseBlocks*growthRate\n",
    "        # 24 + 192 =>nChannels\n",
    "        #print(nChannels)\n",
    "        nOutChannels = int(math.floor(nChannels*reduction)) #math.floor는 소수점 내림.\n",
    "        # nOutChannels => 108\n",
    "        self.trans1 = Transition(nChannels, nOutChannels)\n",
    "        # 1, 108, 25, 25 반반으로 짜름\n",
    "\n",
    "        nChannels = nOutChannels\n",
    "        # 1, 108, 25, 25 => x \n",
    "        # nChannels => 108\n",
    "        self.dense2 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n",
    "        # 1, 300, 25, 25\n",
    "        # 108 + 12*16 = > 300\n",
    "        nChannels += nDenseBlocks*growthRate\n",
    "        nOutChannels = int(math.floor(nChannels*reduction))\n",
    "        self.trans2 = Transition(nChannels, nOutChannels)\n",
    "        # 1, 150, 12 ,12\n",
    "\n",
    "        nChannels = nOutChannels\n",
    "        self.dense3 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n",
    "        # 1, 342, 12, 12\n",
    "        # 192를 계속 더해줌 Tip!\n",
    "        # 150+192=>342\n",
    "        nChannels += nDenseBlocks*growthRate\n",
    "        # print(nChannels)\n",
    "        # nChannels => 342\n",
    "        \n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(nChannels)\n",
    "        self.fc = nn.Linear(nChannels, nClasses)\n",
    "\n",
    "        # layer의 초기화 \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d): # m이 nn.Conv2d이면\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                # n=> size\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                #zero-mean Gaussian distribution Standard deviation\n",
    "                \n",
    "                #print(m.weight.data)\n",
    "                # 가중치 초기화\n",
    "            elif isinstance(m, nn.BatchNorm2d): # m이 nn.BatchNorm2d이면\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "                # bias => 0\n",
    "            elif isinstance(m, nn.Linear): # m이 nn.Linear이면\n",
    "                m.bias.data.zero_()\n",
    "                # bias=> 0\n",
    "        # xavier method => initial differnece thesis ReLu/PReLU 제외\n",
    "        # delving deep into rectifiers: surpassing human level performance on imagenet classification\n",
    "\n",
    "    def _make_dense(self, nChannels, growthRate, nDenseBlocks, bottleneck):\n",
    "        layers = []\n",
    "        for i in range(int(nDenseBlocks)):\n",
    "            if bottleneck:\n",
    "                layers.append(Bottleneck(nChannels, growthRate))\n",
    "            else:\n",
    "                layers.append(SingleLayer(nChannels, growthRate))\n",
    "            nChannels += growthRate\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        # 1, 24, 50, 50\n",
    "        out = self.trans1(self.dense1(out))\n",
    "        # 1, 216, 50, 50\n",
    "        # 1, 108, 25, 25\n",
    "        out = self.trans2(self.dense2(out))\n",
    "        # 1, 300, 25, 25\n",
    "        # 1, 150, 12 ,12\n",
    "        out = self.dense3(out)\n",
    "        # 1, 342, 12 ,12\n",
    "        out = torch.squeeze(F.avg_pool2d(F.relu(self.bn1(out)), 8))\n",
    "        # avg_pool2d out => 1, 342, 1, 1\n",
    "        out = F.log_softmax(self.fc(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "posted-ready",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimension_check():\n",
    "    net = DenseNet(growthRate=12, depth=100, reduction=0.5,\n",
    "                                bottleneck=True, nClasses=7)\n",
    "    x= torch.randn(1,1,48,48)\n",
    "    y= net(x)\n",
    "    print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "amino-toilet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:95: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "dimension_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "final-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,partition,optimizer,criterion):\n",
    "    trainloader = torch.utils.data.DataLoader(partition['train'],\n",
    "                                             batch_size=64,\n",
    "                                             shuffle=True)\n",
    "    net.train()\n",
    "    correct = 0\n",
    "    total =0\n",
    "    train_loss = 0.0\n",
    "    for i, data in enumerate(tqdm(trainloader, 0)):\n",
    "        time.sleep(0.0000001)\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        outputs = net(inputs)\n",
    "        #break\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        #if i % 200 == 0:\n",
    "        #    print(correct,train_loss)\n",
    "    train_loss = train_loss / len(trainloader)\n",
    "    train_acc = 100 * correct / total\n",
    "    return net, train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "acoustic-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, partition):\n",
    "    testloader = torch.utils.data.DataLoader(partition['test'], \n",
    "                                             batch_size=64, \n",
    "                                             shuffle=False, num_workers=2)\n",
    "    net.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(testloader):\n",
    "            time.sleep(0.0000001)\n",
    "            images, labels = data\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        test_acc = 100 * correct / total\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "illegal-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(net, partition, criterion):\n",
    "    valloader = torch.utils.data.DataLoader(partition['val'], \n",
    "                                            batch_size=64, \n",
    "                                            shuffle=False, num_workers=2)\n",
    "    net.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0 \n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(valloader):\n",
    "            time.sleep(0.0000001)\n",
    "            images, labels = data\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs = net(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss = val_loss / len(valloader)\n",
    "        val_acc = 100 * correct / total\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "opposite-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_notebook\n",
    "from tqdm import trange\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-church",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/449 [00:00<?, ?it/s]/home/lab/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:95: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "100%|██████████| 449/449 [01:25<00:00,  5.23it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.52it/s]\n",
      "  0%|          | 1/449 [00:00<01:27,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 88.34, train_loss : 1.57, train_acc : 37.40,val_acc : 44.19,val_loss : 1.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.20it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.70it/s]\n",
      "  0%|          | 1/449 [00:00<01:27,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 88.92, train_loss : 1.23, train_acc : 53.00,val_acc : 55.98,val_loss : 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.19it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.47it/s]\n",
      "  0%|          | 1/449 [00:00<01:26,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 89.02, train_loss : 1.10, train_acc : 58.46,val_acc : 52.66,val_loss : 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.19it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.73it/s]\n",
      "  0%|          | 1/449 [00:00<01:27,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 89.01, train_loss : 1.02, train_acc : 61.48,val_acc : 56.78,val_loss : 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.19it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.46it/s]\n",
      "  0%|          | 1/449 [00:00<01:28,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 89.03, train_loss : 0.95, train_acc : 64.04,val_acc : 58.90,val_loss : 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.19it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.56it/s]\n",
      "  0%|          | 1/449 [00:00<01:27,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 89.01, train_loss : 0.89, train_acc : 66.53,val_acc : 60.52,val_loss : 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.19it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.53it/s]\n",
      "  0%|          | 1/449 [00:00<01:28,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 88.98, train_loss : 0.82, train_acc : 69.28,val_acc : 60.46,val_loss : 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.20it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.67it/s]\n",
      "  0%|          | 1/449 [00:00<01:26,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 88.94, train_loss : 0.76, train_acc : 71.75,val_acc : 61.63,val_loss : 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.20it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.51it/s]\n",
      "  0%|          | 1/449 [00:00<01:28,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 88.96, train_loss : 0.69, train_acc : 74.03,val_acc : 62.05,val_loss : 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.20it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.66it/s]\n",
      "  0%|          | 1/449 [00:00<01:26,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 88.90, train_loss : 0.62, train_acc : 76.83,val_acc : 62.55,val_loss : 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.20it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.70it/s]\n",
      "  0%|          | 1/449 [00:00<01:29,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 88.84, train_loss : 0.56, train_acc : 79.50,val_acc : 58.09,val_loss : 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.20it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.44it/s]\n",
      "  0%|          | 1/449 [00:00<01:27,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 88.92, train_loss : 0.48, train_acc : 82.51,val_acc : 62.19,val_loss : 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.20it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.66it/s]\n",
      "  0%|          | 1/449 [00:00<01:27,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 88.93, train_loss : 0.43, train_acc : 84.23,val_acc : 60.24,val_loss : 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.20it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.61it/s]\n",
      "  0%|          | 1/449 [00:00<01:27,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 88.95, train_loss : 0.36, train_acc : 86.89,val_acc : 57.37,val_loss : 1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.19it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.45it/s]\n",
      "  0%|          | 1/449 [00:00<01:27,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 89.05, train_loss : 0.31, train_acc : 88.79,val_acc : 62.61,val_loss : 1.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.20it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.50it/s]\n",
      "  0%|          | 1/449 [00:00<01:27,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 88.91, train_loss : 0.27, train_acc : 90.03,val_acc : 56.48,val_loss : 1.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.19it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.74it/s]\n",
      "  0%|          | 1/449 [00:00<01:28,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 88.97, train_loss : 0.24, train_acc : 91.40,val_acc : 59.13,val_loss : 1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.20it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.66it/s]\n",
      "  0%|          | 1/449 [00:00<01:29,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 88.90, train_loss : 0.22, train_acc : 92.40,val_acc : 61.74,val_loss : 1.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.19it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.49it/s]\n",
      "  0%|          | 1/449 [00:00<01:27,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 89.02, train_loss : 0.20, train_acc : 92.94,val_acc : 62.25,val_loss : 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.19it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.54it/s]\n",
      "  0%|          | 1/449 [00:00<01:26,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 88.97, train_loss : 0.19, train_acc : 93.34,val_acc : 59.52,val_loss : 2.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.20it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.62it/s]\n",
      "  0%|          | 1/449 [00:00<01:26,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 88.95, train_loss : 0.16, train_acc : 94.41,val_acc : 60.52,val_loss : 1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.19it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.62it/s]\n",
      "  0%|          | 1/449 [00:00<01:28,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 89.01, train_loss : 0.15, train_acc : 94.61,val_acc : 58.68,val_loss : 2.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.20it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.51it/s]\n",
      "  0%|          | 1/449 [00:00<01:28,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 88.96, train_loss : 0.15, train_acc : 94.98,val_acc : 60.32,val_loss : 2.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.20it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.72it/s]\n",
      "  0%|          | 1/449 [00:00<01:27,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 88.92, train_loss : 0.14, train_acc : 95.19,val_acc : 60.96,val_loss : 2.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.20it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.49it/s]\n",
      "  0%|          | 1/449 [00:00<01:28,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 88.91, train_loss : 0.14, train_acc : 95.18,val_acc : 61.91,val_loss : 2.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.20it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.57it/s]\n",
      "  0%|          | 1/449 [00:00<01:27,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 88.95, train_loss : 0.12, train_acc : 95.78,val_acc : 57.73,val_loss : 2.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.20it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.61it/s]\n",
      "  0%|          | 1/449 [00:00<01:27,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 88.94, train_loss : 0.14, train_acc : 95.09,val_acc : 62.16,val_loss : 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.20it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.70it/s]\n",
      "  0%|          | 1/449 [00:00<01:26,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 88.88, train_loss : 0.11, train_acc : 96.27,val_acc : 60.55,val_loss : 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.19it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.70it/s]\n",
      "  0%|          | 1/449 [00:00<01:27,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 88.95, train_loss : 0.12, train_acc : 95.80,val_acc : 61.55,val_loss : 2.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [01:26<00:00,  5.19it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 22.72it/s]\n",
      "  0%|          | 1/449 [00:00<01:27,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 88.95, train_loss : 0.11, train_acc : 96.33,val_acc : 59.01,val_loss : 2.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 118/449 [00:22<01:03,  5.21it/s]"
     ]
    }
   ],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "net = DenseNet(growthRate=12, depth=100, reduction=0.5,\n",
    "                                bottleneck=True, nClasses=7)\n",
    "net.cuda()\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0015, weight_decay=0.00001)\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "train_accs=[]\n",
    "val_accs=[]\n",
    "for epoch in range(100):\n",
    "    ts=time.time()\n",
    "    net, train_loss,train_acc=train(net, partition, optimizer, criterion)\n",
    "    val_loss, val_acc = validate(net, partition, criterion)\n",
    "    te=time.time()\n",
    "    print('time : {:2.2f}, train_loss : {:2.2f}, train_acc : {:2.2f},val_acc : {:2.2f},val_loss : {:2.2f}'.format(te-ts,train_loss,train_acc,val_acc,val_loss))\n",
    "    train_loss=round(train_loss,2)\n",
    "    val_loss=round(val_loss,2)\n",
    "    train_acc=round(train_acc,2)\n",
    "    val_acc=round(val_acc,2)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "test_acc = test(net,partition)\n",
    "test_acc=round(test_acc,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-sapphire",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "colored-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/home/lab/양창희/Emotion Project/fer2013/result_CNN_pytorch/Dense_train_loss.npy\",train_loss)\n",
    "np.save(\"/home/lab/양창희/Emotion Project/fer2013/result_CNN_pytorch/Dense_val_loss.npy\",val_loss)\n",
    "np.save(\"/home/lab/양창희/Emotion Project/fer2013/result_CNN_pytorch/Dense_train_acc.npy\",train_acc)\n",
    "np.save(\"/home/lab/양창희/Emotion Project/fer2013/result_CNN_pytorch/Dense_val_acc.npy\",val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "enabling-employer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[44.19,\n",
       " 55.98,\n",
       " 52.66,\n",
       " 56.78,\n",
       " 58.9,\n",
       " 60.52,\n",
       " 60.46,\n",
       " 61.63,\n",
       " 62.05,\n",
       " 62.55,\n",
       " 58.09,\n",
       " 62.19,\n",
       " 60.24,\n",
       " 57.37,\n",
       " 62.61,\n",
       " 56.48,\n",
       " 59.13,\n",
       " 61.74,\n",
       " 62.25,\n",
       " 59.52,\n",
       " 60.52,\n",
       " 58.68,\n",
       " 60.32,\n",
       " 60.96,\n",
       " 61.91,\n",
       " 57.73,\n",
       " 62.16,\n",
       " 60.55,\n",
       " 61.55,\n",
       " 59.01,\n",
       " 62.33,\n",
       " 63.14,\n",
       " 61.47,\n",
       " 60.69,\n",
       " 62.13,\n",
       " 60.96,\n",
       " 61.08,\n",
       " 59.68,\n",
       " 61.41,\n",
       " 62.66,\n",
       " 60.43,\n",
       " 59.96,\n",
       " 62.75,\n",
       " 62.16,\n",
       " 62.33,\n",
       " 61.41,\n",
       " 62.05,\n",
       " 62.72,\n",
       " 61.27,\n",
       " 62.02,\n",
       " 58.34,\n",
       " 62.02,\n",
       " 61.52,\n",
       " 59.52,\n",
       " 61.27,\n",
       " 62.58,\n",
       " 62.05,\n",
       " 59.1,\n",
       " 60.57,\n",
       " 62.41,\n",
       " 61.77,\n",
       " 63.0,\n",
       " 60.96,\n",
       " 62.47,\n",
       " 61.63,\n",
       " 61.47,\n",
       " 61.49,\n",
       " 62.55,\n",
       " 61.63,\n",
       " 62.69,\n",
       " 60.94,\n",
       " 61.74,\n",
       " 60.55,\n",
       " 61.72,\n",
       " 60.63,\n",
       " 61.58,\n",
       " 62.66,\n",
       " 62.19,\n",
       " 60.02,\n",
       " 62.5,\n",
       " 61.08,\n",
       " 62.16,\n",
       " 61.21,\n",
       " 60.71,\n",
       " 60.57,\n",
       " 62.75,\n",
       " 60.43,\n",
       " 62.41,\n",
       " 61.97,\n",
       " 60.63,\n",
       " 62.86,\n",
       " 61.86,\n",
       " 62.66,\n",
       " 61.74,\n",
       " 61.49,\n",
       " 63.08,\n",
       " 62.16,\n",
       " 61.44,\n",
       " 61.86,\n",
       " 60.88]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-spectrum",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
