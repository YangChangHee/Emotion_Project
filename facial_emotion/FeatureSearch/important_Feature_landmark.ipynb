{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88098810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class SBS():\n",
    "    def __init__(self, estimator, k_features, scoring=accuracy_score,\n",
    "                 test_size=0.25, random_state=1):\n",
    "        self.scoring = scoring\n",
    "        self.estimator = clone(estimator)\n",
    "        self.k_features = k_features\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = \\\n",
    "            train_test_split(X, y, test_size=self.test_size,\n",
    "                             random_state=self.random_state)\n",
    "\n",
    "        dim = X_train.shape[1]\n",
    "        self.indices_ = tuple(range(dim))\n",
    "        self.subsets_ = [self.indices_]\n",
    "        score = self._calc_score(X_train, y_train, \n",
    "                                 X_test, y_test, self.indices_)\n",
    "        self.scores_ = [score]\n",
    "\n",
    "        while dim > self.k_features:\n",
    "            scores = []\n",
    "            subsets = []\n",
    "\n",
    "            for p in combinations(self.indices_, r=dim - 1):\n",
    "                score = self._calc_score(X_train, y_train, \n",
    "                                         X_test, y_test, p)\n",
    "                scores.append(score)\n",
    "                subsets.append(p)\n",
    "\n",
    "            best = np.argmax(scores)\n",
    "            self.indices_ = subsets[best]\n",
    "            self.subsets_.append(self.indices_)\n",
    "            dim -= 1\n",
    "\n",
    "            self.scores_.append(scores[best])\n",
    "        self.k_score_ = self.scores_[-1]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:, self.indices_]\n",
    "\n",
    "    def _calc_score(self, X_train, y_train, X_test, y_test, indices):\n",
    "        self.estimator.fit(X_train[:, indices], y_train)\n",
    "        y_pred = self.estimator.predict(X_test[:, indices])\n",
    "        score = self.scoring(y_test, y_pred)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a846ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=np.load(\"gradient_emo.npy\")\n",
    "label=np.load(\"label_landmark.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8254d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(input_data, label, test_size=0.3, \n",
    "                     stratify=label,\n",
    "                     random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a9e6a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ef22cc",
   "metadata": {},
   "source": [
    "# 너무 오래걸림 문제점 파악이 필요할듯 보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9275f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# 특성을 선택합니다.\n",
    "sbs = SBS(knn, k_features=1)\n",
    "sbs.fit(X_train_std, y_train)\n",
    "\n",
    "# 특성 조합의 성능 그래프를 출력합니다.\n",
    "k_feat = [len(k) for k in sbs.subsets_]\n",
    "\n",
    "plt.plot(k_feat, sbs.scores_, marker='o')\n",
    "plt.ylim([0.7, 1.02])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of features')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13c13a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=500,\n",
    "                                random_state=1)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "importances = forest.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9054e703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01858425, 0.01887012, 0.01853466, 0.01926674, 0.01883289,\n",
       "       0.01926885, 0.01840044, 0.01902384, 0.02086764, 0.02045839,\n",
       "       0.01940418, 0.01967392, 0.01928808, 0.01822827, 0.01802114,\n",
       "       0.01802974, 0.02501672, 0.01677008, 0.01293605, 0.01396234,\n",
       "       0.01405781, 0.0142767 , 0.01798102, 0.02677985, 0.01807252,\n",
       "       0.01822505, 0.01613308, 0.0090796 , 0.01045325, 0.0101456 ,\n",
       "       0.00984411, 0.01799797, 0.00891687, 0.01626354, 0.01303974,\n",
       "       0.00922848, 0.01669801, 0.00940068, 0.01897043, 0.01599365,\n",
       "       0.00937221, 0.02014969, 0.02839903, 0.00842453, 0.00939246,\n",
       "       0.02691984, 0.02028689, 0.02386743, 0.01759068, 0.01208076,\n",
       "       0.01100182, 0.01804166, 0.0193109 , 0.01032703, 0.00992478,\n",
       "       0.02152883, 0.04627327, 0.01172724, 0.01038468])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6daf609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "791ae772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([56, 42, 45, 23, 16, 47, 55,  8,  9, 46, 41, 11, 10, 52, 12,  5,  3,\n",
       "        7, 38,  1,  4,  0,  2,  6, 13, 25, 24, 51, 15, 14, 31, 22, 48, 17,\n",
       "       36, 33, 26, 39, 21, 20, 19, 34, 18, 49, 57, 50, 28, 58, 53, 29, 54,\n",
       "       30, 37, 44, 40, 35, 27, 32, 43])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2477d374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n"
     ]
    }
   ],
   "source": [
    "label_name=[i+1 for i in range(59)]\n",
    "print(label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b877b5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) 57                             0.046273\n",
      " 2) 43                             0.028399\n",
      " 3) 46                             0.026920\n",
      " 4) 24                             0.026780\n",
      " 5) 17                             0.025017\n",
      " 6) 48                             0.023867\n",
      " 7) 56                             0.021529\n",
      " 8) 9                              0.020868\n",
      " 9) 10                             0.020458\n",
      "10) 47                             0.020287\n",
      "11) 42                             0.020150\n",
      "12) 12                             0.019674\n",
      "13) 11                             0.019404\n",
      "14) 53                             0.019311\n",
      "15) 13                             0.019288\n",
      "16) 6                              0.019269\n",
      "17) 4                              0.019267\n",
      "18) 8                              0.019024\n",
      "19) 39                             0.018970\n",
      "20) 2                              0.018870\n",
      "21) 5                              0.018833\n",
      "22) 1                              0.018584\n",
      "23) 3                              0.018535\n",
      "24) 7                              0.018400\n",
      "25) 14                             0.018228\n",
      "26) 26                             0.018225\n",
      "27) 25                             0.018073\n",
      "28) 52                             0.018042\n",
      "29) 16                             0.018030\n",
      "30) 15                             0.018021\n",
      "31) 32                             0.017998\n",
      "32) 23                             0.017981\n",
      "33) 49                             0.017591\n",
      "34) 18                             0.016770\n",
      "35) 37                             0.016698\n",
      "36) 34                             0.016264\n",
      "37) 27                             0.016133\n",
      "38) 40                             0.015994\n",
      "39) 22                             0.014277\n",
      "40) 21                             0.014058\n",
      "41) 20                             0.013962\n",
      "42) 35                             0.013040\n",
      "43) 19                             0.012936\n",
      "44) 50                             0.012081\n",
      "45) 58                             0.011727\n",
      "46) 51                             0.011002\n",
      "47) 29                             0.010453\n",
      "48) 59                             0.010385\n",
      "49) 54                             0.010327\n",
      "50) 30                             0.010146\n",
      "51) 55                             0.009925\n",
      "52) 31                             0.009844\n",
      "53) 38                             0.009401\n",
      "54) 45                             0.009392\n",
      "55) 41                             0.009372\n",
      "56) 36                             0.009228\n",
      "57) 28                             0.009080\n",
      "58) 33                             0.008917\n",
      "59) 44                             0.008425\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-81b8d856881d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m plt.xticks(range(X_train.shape[1]), \n\u001b[0;32m---> 14\u001b[0;31m            label_name[indices], rotation=90)\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, \n",
    "                            label_name[indices[f]], \n",
    "                            importances[indices[f]]))\n",
    "\n",
    "plt.title('Feature Importance')\n",
    "plt.bar(range(X_train.shape[1]), \n",
    "        importances[indices],\n",
    "        align='center')\n",
    "\n",
    "plt.xticks(range(X_train.shape[1]), \n",
    "           label_name[indices], rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9284f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 임계 조건을 만족하는 샘플의 수: 11\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "sfm = SelectFromModel(forest, threshold=0.02, prefit=True)\n",
    "X_selected = sfm.transform(X_train)\n",
    "print('이 임계 조건을 만족하는 샘플의 수:', X_selected.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2530aaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) 57                             0.046273\n",
      " 2) 43                             0.028399\n",
      " 3) 46                             0.026920\n",
      " 4) 24                             0.026780\n",
      " 5) 17                             0.025017\n",
      " 6) 48                             0.023867\n",
      " 7) 56                             0.021529\n",
      " 8) 9                              0.020868\n",
      " 9) 10                             0.020458\n",
      "10) 47                             0.020287\n",
      "11) 42                             0.020150\n"
     ]
    }
   ],
   "source": [
    "for f in range(X_selected.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, \n",
    "                            label_name[indices[f]], \n",
    "                            importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e546363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
